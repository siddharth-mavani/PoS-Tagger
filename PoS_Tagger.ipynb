{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FtY9R2cR3MbC"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from nltk.corpus import treebank, brown, conll2000\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we-1bWWb3eb3",
        "outputId": "d7f7c5b1-8f93-4b59-b11b-bed9c2c6f3c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('treebank')\n",
        "nltk.download('brown')\n",
        "nltk.download('conll2000')\n",
        "nltk.download('universal_tagset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs4jNzrg3tgq",
        "outputId": "bbb6affa-d1ad-4a0b-8ec2-e4e07f5a880b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')]\n",
            "Dataset size: 72202\n"
          ]
        }
      ],
      "source": [
        "tagged_sentences = treebank.tagged_sents(tagset='universal') + brown.tagged_sents(tagset='universal') + conll2000.tagged_sents(tagset='universal')\n",
        "\n",
        "print(tagged_sentences[0])\n",
        "print(f\"Dataset size: {len(tagged_sentences)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-ZZF3PQ50vs",
        "outputId": "60da1f32-9c1a-4785-e2f5-ea4399db2852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
            "['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.']\n"
          ]
        }
      ],
      "source": [
        "sentences = []\n",
        "tags = []\n",
        "\n",
        "for sentence in tagged_sentences:\n",
        "    sentence_words = []\n",
        "    sentence_tags = []\n",
        "    for word, tag in sentence:\n",
        "        sentence_words.append(word)\n",
        "        sentence_tags.append(tag)\n",
        "    sentences.append(sentence_words)\n",
        "    tags.append(sentence_tags)\n",
        "\n",
        "print(sentences[0])\n",
        "print(tags[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0ih2uoL6WZn",
        "outputId": "d389a0d9-05ba-426d-8e13-d4ea705230f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72202 72202\n"
          ]
        }
      ],
      "source": [
        "print(len(sentences), len(tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-vPJNhWs6X-0"
      },
      "outputs": [],
      "source": [
        "train_ratio = 0.75\n",
        "test_ratio = 0.15\n",
        "val_ratio = 0.1\n",
        "\n",
        "train_sentences, test_sentences, train_tags, test_tags = train_test_split(sentences, tags, test_size=1 - train_ratio, random_state=1)\n",
        "val_sentences, test_sentences, val_tags, test_tags = train_test_split(test_sentences, test_tags, test_size=test_ratio/(test_ratio + val_ratio), random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "armKxa0L7tz2",
        "outputId": "afc4982d-fe2f-46bd-cf60-1e7d3caa8645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "54151 54151\n",
            "7220 7220\n",
            "10831 10831\n"
          ]
        }
      ],
      "source": [
        "print(len(train_sentences), len(train_tags))\n",
        "print(len(val_sentences), len(val_tags))\n",
        "print(len(test_sentences), len(test_tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zF3NM3V6779q"
      },
      "outputs": [],
      "source": [
        "sentence_tokenizer = keras.preprocessing.text.Tokenizer(oov_token=\"<OOV>\")\n",
        "sentence_tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "tag_tokenizer = keras.preprocessing.text.Tokenizer(oov_token=\"<OOV>\")\n",
        "tag_tokenizer.fit_on_texts(train_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uUZcbnrW_jRs"
      },
      "outputs": [],
      "source": [
        "MAX_SEN_LEN = max([len(sentence) for sentence in train_sentences])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-FKG5VwM8_16"
      },
      "outputs": [],
      "source": [
        "train_sentence_sequence = sentence_tokenizer.texts_to_sequences(train_sentences)\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(train_sentence_sequence, padding=\"post\", maxlen=MAX_SEN_LEN)\n",
        "\n",
        "train_tag_sequence = tag_tokenizer.texts_to_sequences(train_tags)\n",
        "y_train = keras.preprocessing.sequence.pad_sequences(train_tag_sequence, padding=\"post\", maxlen=MAX_SEN_LEN)\n",
        "\n",
        "val_sentence_sequence = sentence_tokenizer.texts_to_sequences(val_sentences)\n",
        "x_val = keras.preprocessing.sequence.pad_sequences(val_sentence_sequence, padding=\"post\", maxlen=MAX_SEN_LEN)\n",
        "\n",
        "val_tag_sequence = tag_tokenizer.texts_to_sequences(val_tags)\n",
        "y_val = keras.preprocessing.sequence.pad_sequences(val_tag_sequence, padding=\"post\", maxlen=MAX_SEN_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApBikzWa9IOS",
        "outputId": "0900c502-c637-4412-f664-5d827ce1a864"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['This', 'may', 'be', 'due', 'to', 'the', 'heavy', 'interlobular', 'connective', 'tissue', 'barriers', 'present', '.'] 13\n",
            "[   27    86    21   479     7     2   920 10903 20547  3327  5644   337\n",
            "     4     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0] 161\n",
            "[6 3 3 7 5 6 7 7 7 2 2 8 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0] 161\n"
          ]
        }
      ],
      "source": [
        "print(train_sentences[0], len(train_sentences[0]))\n",
        "print(x_train[0], len(x_train[0]))\n",
        "print(y_train[0], len(y_train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fvXfTKI6-TMg"
      },
      "outputs": [],
      "source": [
        "y_train_one_hot = keras.utils.to_categorical(y_train, num_classes=len(tag_tokenizer.word_index) + 1)\n",
        "y_val_one_hot = keras.utils.to_categorical(y_val, num_classes=len(tag_tokenizer.word_index) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDPIRS1MJNrV",
        "outputId": "ed5cc563-d33b-4b34-9e44-6c8d6b82301e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52042 14\n"
          ]
        }
      ],
      "source": [
        "num_tokens = len(sentence_tokenizer.word_index) + 1\n",
        "num_classes = len(tag_tokenizer.word_index) + 1\n",
        "embedding_dim = 128\n",
        "\n",
        "print(num_tokens, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpI7RXIOKTTF",
        "outputId": "d1eb1b2a-e874-4da3-b924-0c06bf59c222"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(0)\n",
        "\n",
        "input = layers.Input(shape=(MAX_SEN_LEN,))\n",
        "model = layers.Embedding(input_dim=num_tokens, output_dim=embedding_dim, input_length=MAX_SEN_LEN)(input)\n",
        "model = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(model)\n",
        "outputs = layers.TimeDistributed(layers.Dense(num_classes, activation=\"softmax\"))(model)\n",
        "\n",
        "model = models.Model(inputs=input, outputs=outputs)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "IMp_u2nsQNen",
        "outputId": "cdffafdd-d66f-4316-9dd3-1a460d0c18cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,661,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,598</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m161\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m6,661,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m263,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │           \u001b[38;5;34m3,598\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,928,142</span> (26.43 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,928,142\u001b[0m (26.43 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,928,142</span> (26.43 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,928,142\u001b[0m (26.43 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b4B9gJBnp-l",
        "outputId": "b723e82a-a05b-43e8-8a1d-2d599d914ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 131ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.9961 - val_loss: 0.0122\n",
            "Epoch 2/10\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 132ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9961 - val_loss: 0.0123\n",
            "Epoch 3/10\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 134ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.9961 - val_loss: 0.0126\n",
            "Epoch 4/10\n",
            "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 131ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 0.9961 - val_loss: 0.0128\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a26121dd240>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "model.fit(x_train, y_train_one_hot, batch_size=256, epochs=10, validation_data=(x_val, y_val_one_hot), callbacks=[es_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dc1de_6ryh_B"
      },
      "outputs": [],
      "source": [
        "test_sentence_sequence = sentence_tokenizer.texts_to_sequences(test_sentences)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(test_sentence_sequence, padding=\"post\", maxlen=MAX_SEN_LEN)\n",
        "\n",
        "test_tag_sequence = tag_tokenizer.texts_to_sequences(test_tags)\n",
        "y_test = keras.preprocessing.sequence.pad_sequences(test_tag_sequence, padding=\"post\", maxlen=MAX_SEN_LEN)\n",
        "\n",
        "y_test_one_hot = keras.utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9xWS2QPy4RR",
        "outputId": "724d53dd-b581-4d5f-a157-b6bc75f8eadf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9961 - loss: 0.0132\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.012813247740268707, 0.9961857795715332]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(x_test, y_test_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Puk0aXFQ3kSG"
      },
      "outputs": [],
      "source": [
        "def inference(samples):\n",
        "  sentence_sequence = sentence_tokenizer.texts_to_sequences(samples)\n",
        "  padded_sentence_sequence = keras.preprocessing.sequence.pad_sequences(sentence_sequence, padding=\"post\", maxlen=MAX_SEN_LEN)\n",
        "\n",
        "  predicted_tags = model.predict(padded_sentence_sequence)\n",
        "\n",
        "  sentence_tags = []\n",
        "  for i, preds in enumerate(predicted_tags):\n",
        "\n",
        "    tags_sequence = [np.argmax(p) for p in preds[:len(sentence_sequence[i])]]\n",
        "\n",
        "    words = [sentence_tokenizer.index_word[w] for w in sentence_sequence[i]]\n",
        "    tags = [tag_tokenizer.index_word[t] for t in tags_sequence]\n",
        "\n",
        "    sentence_tags.append(list(zip(words, tags)))\n",
        "\n",
        "  return sentence_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtv23cLC4iYA",
        "outputId": "e5e52fe1-a86e-4900-cca0-4d68f9208ca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
          ]
        }
      ],
      "source": [
        "samples = [\n",
        "    \"My name is Darsh\",\n",
        "    \"The quick brown fox jumps over the lazy dog\"\n",
        "    ]\n",
        "\n",
        "sentence_tags = inference (samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9nGlW7j7K_r",
        "outputId": "0c2c40ee-4255-40a4-8d2e-fa4bf745db3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('the', 'det'), ('quick', 'adj'), ('brown', 'noun'), ('fox', 'noun'), ('jumps', 'noun'), ('over', 'adp'), ('the', 'det'), ('lazy', 'adj'), ('dog', 'noun')]\n"
          ]
        }
      ],
      "source": [
        "print(sentence_tags[1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
